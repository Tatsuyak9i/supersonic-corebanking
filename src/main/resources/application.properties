# Configure the Kafka source (we read from it)
mp.messaging.incoming.external-events.connector=smallrye-kafka
mp.messaging.incoming.external-events.topic=external-events
mp.messaging.incoming.external-events.value.deserializer= com.redhat.supersonic.corebanking.util.TransferDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.internal-events.connector=smallrye-kafka
mp.messaging.outgoing.internal-events.topic=internal-events
mp.messaging.outgoing.internal-events.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer

# configure your datasource
quarkus.datasource.db-kind = postgresql
quarkus.datasource.username = user01
quarkus.datasource.password = redhat
quarkus.datasource.jdbc.url = jdbc:postgresql://demo-crdb-tls-public:26257/bank

# drop and create the database at startup (use `update` to only update the schema)
quarkus.hibernate-orm.database.generation = update

# set the Kubernetes namespace which will be used to run the application
quarkus.container-image.group=demo1
# set the container image registry - this is the standard URL used to refer to the internal OpenShift registry
quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000

quarkus.s2i.base-jvm-image=quay.io/quarkus/centos-quarkus-native-s2i:latest
quarkus.s2i.base-native-image=quay.io/quarkus/centos-quarkus-native-s2i:latest
quarkus.kubernetes.deployment-target=knative